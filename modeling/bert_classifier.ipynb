{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c4cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4573c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57898618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lots of parking. Lots nice hotels in the area ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The one thing I want to caution is bring wood ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very little and very expensive parking, and th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This property ruined my birthday weekend with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We returned to the parking area and sat on som...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Lots of parking. Lots nice hotels in the area ...      2\n",
       "1  The one thing I want to caution is bring wood ...      3\n",
       "2  Very little and very expensive parking, and th...      0\n",
       "3  This property ruined my birthday weekend with ...      0\n",
       "4  We returned to the parking area and sat on som...      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('samples.csv')\n",
    "\n",
    "df['label'] = df['label'].replace({\n",
    "    'negative': 0, \n",
    "    'neutral': 1, \n",
    "    'positive': 2, \n",
    "    'unrelated': 3,})\n",
    "\n",
    "print(len(df))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a7ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['negative', 'neutral', 'positive', 'unrelated']\n",
    "\n",
    "train_df = df.iloc[:1600]\n",
    "test_df = df.iloc[1600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da29ef",
   "metadata": {},
   "source": [
    "### Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d6e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def data_processing(df):\n",
    "    \"\"\"Process the data for training and testing based on bert tokenizer\"\"\"\n",
    "    sequences = df['text'].tolist()\n",
    "    labels = df['label'].tolist()\n",
    "    encodings = tokenizer(sequences, truncation=True, padding=True)\n",
    "\n",
    "    class TextDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['label'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    return TextDataset(encodings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649d9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute the metrics for the model\"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd649af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# adjust the number based on classification labels\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5) \n",
    "\n",
    "global_best_model = None\n",
    "global_best_f1 = 0\n",
    "\n",
    "def training_objective(trial):\n",
    "    \"\"\"Define the training process using the bert model\"\"\"\n",
    "    global global_best_model\n",
    "    global global_best_f1\n",
    "    \n",
    "    # Define the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          \n",
    "        num_train_epochs=trial.suggest_int(\"num_train_epochs\",1,5), \n",
    "        per_device_train_batch_size=trial.suggest_categorical(\"per_device_train_batch_size\", [16,32,64]),  \n",
    "        per_device_eval_batch_size=64,  \n",
    "        warmup_steps=500,                \n",
    "        weight_decay=0.01,               \n",
    "        #logging_dir='./logs',  \n",
    "    )\n",
    "    \n",
    "    total_f1 = 0\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "        train_fold = data_processing(train_df.iloc[train_index])\n",
    "        val_fold = data_processing(train_df.iloc[val_index])\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model, \n",
    "            args=training_args,\n",
    "            train_dataset=train_fold,\n",
    "            eval_dataset=val_fold,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluate the model\n",
    "        eval_result = trainer.evaluate()\n",
    "        total_f1 += eval_result['eval_f1']\n",
    "\n",
    "    mean_f1 = total_f1 / kf.get_n_splits()\n",
    "    if mean_f1 > global_best_f1:\n",
    "        global_best_f1 = mean_f1\n",
    "        global_best_model = model\n",
    "        # Uncomment the following line to save the best model\n",
    "        #global_best_model = trainer.save_model(\"best_model\") \n",
    "    trial.set_user_attr('mean_f1', mean_f1)\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f1fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(training_objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168447a5",
   "metadata": {},
   "source": [
    "### Report model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0542f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved best model\n",
    "best_model = BertForSequenceClassification.from_pretrained(\"./best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64dc1033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd21af08aeed41c49fc4e66577fda81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.12%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2041c42238e4644b2cb1992db162633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 90.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92       165\n",
      "     neutral       0.71      0.53      0.61        19\n",
      "    positive       0.93      0.93      0.93       190\n",
      "   unrelated       0.88      0.54      0.67        26\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.85      0.74      0.78       400\n",
      "weighted avg       0.90      0.90      0.89       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_processing(df[:1600])\n",
    "test_dataset = data_processing(df[1600:])\n",
    "\n",
    "# Define a new trainer with the best model\n",
    "best_trainer = Trainer(model=best_model)\n",
    "\n",
    "# Get predictions on training set\n",
    "train_predictions = best_trainer.predict(train_dataset)\n",
    "train_preds = np.argmax(train_predictions.predictions, axis=1)\n",
    "acc_train = accuracy_score(train_dataset.labels, train_preds)\n",
    "\n",
    "print(f\"train accuracy: {acc_train*100:.2f}%\")\n",
    "\n",
    "# Get predictions on testing set\n",
    "test_predictions = best_trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
    "acc_test = accuracy_score(test_dataset.labels, test_preds)\n",
    "print(f\"test accuracy: {acc_test*100:.2f}%\")\n",
    "\n",
    "print(classification_report(test_dataset.labels, test_preds, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfcb6d",
   "metadata": {},
   "source": [
    "### Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd33845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from process_text import *\n",
    "\n",
    "mapping = {0: 'negative', 1: 'neutral', 2: 'positive', 3: 'unrelated'} \n",
    "\n",
    "def classify_text(df):\n",
    "    \"\"\"Classify the text based on the trained bert model\"\"\"\n",
    "    df['parking_text'] = df['text'].apply(process_comment)\n",
    "    df = df.dropna(subset=['parking_text'])\n",
    "    df = df[df['parking_text'] != '']\n",
    "    sequences = df['parking_text'].astype(str).tolist()\n",
    "    tokenized_sequences = tokenizer(sequences, truncation=True, padding=True)\n",
    "    new_dataset = InferenceDataset(tokenized_sequences)\n",
    "    predictions = best_trainer.predict(new_dataset)\n",
    "    predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "    df['predicted_labels'] = predicted_labels\n",
    "    df['predicted_labels'] = df['predicted_labels'].replace(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3768a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the trained model to classify the comment for each file\n",
    "\n",
    "save_folder = 'parking-pos-review-classification'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "read_folder = 'parking-pos-review'\n",
    "read_files = [file for file in os.listdir(read_folder) if file.endswith('.csv')]\n",
    "read_files = sorted(read_files)\n",
    "print(read_files)\n",
    "    \n",
    "for read_file in read_files:\n",
    "    save_file = read_file.split('.csv')[0] + \"_classification.csv\"\n",
    "    read_filepath = os.path.join(read_folder, read_file)\n",
    "    print(f'----- process {read_filepath}')\n",
    "    save_filepath = os.path.join(save_folder, save_file)\n",
    "    reader = pd.read_csv(read_filepath, chunksize=1000)\n",
    "    chunks = []\n",
    "    for chunk in reader:\n",
    "        chunk = classify_text(chunk)\n",
    "        chunks.append(chunk)\n",
    "    df = pd.concat(chunks)\n",
    "    df.to_csv(save_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6baa16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
